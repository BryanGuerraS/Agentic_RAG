# ğŸš€ RAG Tradicional con Langchain y GradioğŸŒŸ
Â¡Bienvenido al proyecto! ğŸ‰ Este repositorio contiene una implementaciÃ³n de una API que utiliza Gradio para procesar preguntas, buscar texto relevante y generar respuestas utilizando un modelo de lenguaje grande (LLM). La aplicaciÃ³n se integra con Cohere para la generaciÃ³n de embeddings y ChromaDB para la bÃºsqueda de similitudes.

## ğŸ§  Principales Insights o Mejoras del Proyecto
- **Manejo de API Keys en archivo ".env"**: La gestiÃ³n de las claves de API se realiza de manera segura a travÃ©s de un archivo `.env`.
- **Framework de Llama Index y OpenAI para anÃ¡lisis de Chunk Size Ideal**: Se implementÃ³ el framework de Llama Index junto con OpenAI para ajustar el tamaÃ±o Ã³ptimo de los fragmentos (chunks) para la bÃºsqueda de informaciÃ³n.
- **Framework de Langchain y Cohere para el procesamiento de consultas**: Se utiliza Langchain y Cohere para el procesamiento avanzado de consultas.
- **ActualizaciÃ³n del splitter de tamaÃ±o fijo a recursivo adicional al overlap**: Se mejorÃ³ la forma en que se dividen los documentos, implementando un splitter recursivo con un solapamiento adicional.
- **ActualizaciÃ³n del flujo de trabajo para detectar el idioma y responder en el mismo**: Ahora la API detecta el idioma de las preguntas y responde en el mismo idioma.


## ğŸŒŸ CaracterÃ­sticas principales
- ğŸ—‚ï¸ Procesamiento de documentos `.docx` y `.pdf` para extraer informaciÃ³n relevante.  
- ğŸ” Almacenamiento de embeddings en **ChromaDB** para bÃºsqueda eficiente de similitudes.  
- ğŸ¤– Respuestas concisas y personalizadas generadas con modelos LLM.  
- ğŸ“¦ Despliegue simplificado con Docker.  


## ğŸ“‚ Estructura del proyecto
```console
ğŸ“ app  
â”œâ”€â”€ cargar_en_chroma_db.py  # Carga y almacenamiento de documentos en ChromaDB.
â”œâ”€â”€ config.py               # GestiÃ³n y validaciÃ³n de variables de entorno.
â”œâ”€â”€ inicializar_db.py       # InicializaciÃ³n y combinaciÃ³n de documentos preprocesados.
â”œâ”€â”€ models.py               # DefiniciÃ³n de los modelos de datos.
ğŸ“ documents
â”œâ”€â”€ preprocessed/           # Documentos ya procesados.
â”œâ”€â”€ uploaded/               # Documentos cargados por el usuario.
ğŸ“ chroma_db
â”œâ”€â”€ preprocessed/           # Base de datos de embeddings para documentos preprocesados.
â”œâ”€â”€ uploaded/               # Base de datos de embeddings para documentos cargados.
Dockerfile                  # ConfiguraciÃ³n para construir la imagen Docker.
main.py                     # Archivo principal de la aplicaciÃ³n.
requirements.txt            # LibrerÃ­as requeridas.
```

## ğŸš€ CÃ³mo ejecutar el proyecto
### 1ï¸âƒ£ Requisitos previos
- ğŸ Python 3.9+  
- ğŸ³ Docker instalado.  
- ğŸ§ª Postman o cualquier cliente HTTP para probar la API.

### 2ï¸âƒ£ EjecuciÃ³n local
1. Clona el repositorio:
```console
git clone https://github.com/BryanGuerraS/Traditional-RAG-with-Gradio-Upload-Files.git
cd Traditional-RAG-with-Gradio-Upload-Files
```
2. Crea un entorno virtual e instala las dependencias:
```console
python -m venv env
source env/bin/activate  # En Windows: .\venv\Scripts\activate
pip install -r requirements.txt
```

3. Crea un archivo .env en la raÃ­z del proyecto con las siguientes claves:
```console
LANGCHAIN_API_KEY=tu_clave_aqui
COHERE_API_KEY=tu_clave_aqui
```

4. Inicia la API
```console
uvicorn main:app --reload
```
5. Prueba la API
Prueba la API en: http://127.0.0.1:7860/

### 3ï¸âƒ£ EjecuciÃ³n con Docker
1. Construye la imagen Docker:
```console
docker build -t rag_gradio .
```
2. Ejecuta el contenedor:
```console
docker run -p 8000:8000 rag_gradio
```
3. Prueba la API:
- La API estarÃ¡ disponible en: http://127.0.0.1:7860/


## ğŸ› ï¸ Endpoints principales
### Principales preguntas:
- Procesa una pregunta y genera una respuesta basada en documentos relevantes.


```

## ğŸ“– DocumentaciÃ³n adicional
- Docker: Este proyecto incluye un archivo Dockerfile que permite desplegar la API rÃ¡pidamente en un contenedor.
- MÃ³dulos separados: CÃ³digo modular y bien documentado para facilitar su mantenimiento y escalabilidad.

## ğŸŒ Contribuciones
Â¡Las contribuciones son bienvenidas! Si encuentras un problema o deseas agregar una mejora, por favor abre un issue o envÃ­a un pull request. ğŸ™Œ